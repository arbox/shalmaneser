#################################################
# This is a sample experiment file
# with explanations of all features 
# that can be set for the FRED system.
#
# To start your own experiment,
# replace all occurrences of 
# %...% by values of your choice.
#
# When a feature is set twice in the sample experiment file,
# this means you can give several features of this type
#
# Boolean features may be omitted and are false by default.
#
# Experiment file lines that start with '#'
# are comments and are ignored. Empty lines are ignored as well. 

########################
# Experiment description
#

# ID identifying this experiment and all its data
# please do not use spaces inside the experiment ID
experiment_ID = exp_fred_salsa

# targets:
# if apply_to_all_known_targets is set to true,
# disambiguate all words for which we have training data
# when performing task "test" (i.e. applying trained classifiers)
apply_to_all_known_targets = true

# Enduser mode?
# The idea is that the enduser will only _apply_
# pre-trained classifiers. So in enduser mode many 
# options are disallowed.
enduser_mode = false


# print warnings and 
# give detailed progress reports
verbose = true


############################
# Paths
# - fred_directory: directory where Fred puts its internal data
# - directory_output: 
#   redirect system output of disambiguated text (in SalsaTigerXML)
#   to another directory. 
#   If you do not set anything here, output is to
#   <fred_directory>/<experiment_ID>/output/stxml
# - classifier_dir:
#   Write trained classifiers to this directory.
#   If you do not set this parameter, classifiers are written to
#   <fred_directory>/<experiment_ID>/classifiers

fred_directory = /home/arbox/work_space/shalm/dev/trunk/output

# - preproc_descr_file_train / ...test
#   where the experiment file for frprep is located
#   (preprocessing for Fred and Rosy)
#   for the preprocessing of the data used in this experiment
#
#   give one preprocessing file name for the training data
#   and one for the test data
#   (If you only ever use test data in this experiment, you only
#   need to give preproc_descr_file_test, and vice versa for training data.)
preproc_descr_file_train = /home/arbox/work_space/shalm/dev/trunk/program_de/SampleExperimentFiles.salsa/prp_train.salsa
preproc_descr_file_test = /home/arbox/work_space/shalm/dev/trunk/program_de/SampleExperimentFiles.salsa/prp_test.salsa

#####################
# noncontiguous input?
# if so, set 'noncontiguous_input' to 'true' (default is 'false')
# Also give the larger corpus from which the input sentences are:
# - directory
# - format: same possibilities as for frprep format
# - encoding: same possibilities as for frprep encoding

noncontiguous_input = false
#larger_corpus_dir = 
larger_corpus_format = SalsaTigerXML
#larger_corpus_encoding = iso


#################
# Features

# bag-of-words context, with given context size,
# for example:
 feature = context 50
 feature = context 2
#
# (you can give more than one context feature line!)
#
# other possible features:
# feature = syntax
# feature = synsem
#
# syntax: grammatical functions
# synsem: grammatical functions plus headwords

#feature = context % %contextsize%
feature = syntax

# How to handle training data that is labeled
# with multiple sense labels?
# - binarize (default): This works only with binary classifiers. 
#   When featurizing for the binary classifiers, consider an item 
#   positive if its set of assigned labels includes the 
#   label for this binary classifier.
# - repeat: Repeat the instance, once for each
#   sense label that has been assigned. (Basically, treat it
#   as N instances with equal features but different labels.)
# - join: join all the assigned senses into one combined sense
#   and treat that as a separate sense to train on.
# - keep: keep as multiple sense labels. (Note that this
#   makes sense only for classifiers that can deal with
#   multiple labels.)

#handle_multilabel = binarize
handle_multilabel = repeat

# What to do with numerical features?
# - keep: just leave as is
# - repeat: for a feature with max. numerical value N,
#   use N binary features
# - bin: use a fixed number of bins, e.g. 5, then
#   if feature value > 20: set all bins to 1,
#   if feature value > 10: set the first four bins to 1, 
#   etc.
#   default: bin.
#numerical_features = bin
numerical_features = keep

# Binary classifiers, or n-ary classifiers?
# if binary classifiers, set 'binary_classifiers = true'
# default is 'false'.
binary_classifiers = false

#################
# Fred internal settings

# what kind of classifier to use?
#
# format:
# <classifier type> <path> <optionally another path>
#
# for maxent, give first the path where maxent resides, 
# then <where_shalmaneser_resides>/program/tools/maxent
classifier = maxent /opt/OpenNLP-maxent/2.4.0 /home/arbox/work_space/shalm/dev/trunk/program_de/tools/maxent/


# for binary classifiers, you can set the pseudolabel
# on the 'negative' sense.
# Default is 'NONE'      
negsense = NONE
